{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T09:10:26.969382Z","iopub.status.busy":"2024-02-24T09:10:26.968995Z","iopub.status.idle":"2024-02-24T09:10:26.976136Z","shell.execute_reply":"2024-02-24T09:10:26.975093Z","shell.execute_reply.started":"2024-02-24T09:10:26.969350Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from nltk.tokenize import word_tokenize\n","from torchtext.vocab import build_vocab_from_iterator\n","import string\n","import random\n","import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","from tqdm import tqdm\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>english_caption</th>\n","      <th>bengali_caption</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>a child in a pink dress is climbing up a set o...</td>\n","      <td>একটি গোলাপী জামা পরা বাচ্চা মেয়ে একটি বাড়ির প্...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>a girl going into a wooden building .</td>\n","      <td>একটি মেয়ে শিশু একটি কাঠের বাড়িতে ঢুকছে</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>a little girl climbing into a wooden playhouse .</td>\n","      <td>একটি বাচ্চা তার কাঠের খেলাঘরে উঠছে ।</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>a little girl climbing the stairs to her playh...</td>\n","      <td>ছোট মেয়েটি তার খেলার ঘরের সিড়ি বেয়ে উঠছে</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>a little girl in a pink dress going into a woo...</td>\n","      <td>গোলাপি জামা পড়া ছোট একটি মেয়ে একটি কাঠের তৈরি...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                     english_caption  \\\n","0  a child in a pink dress is climbing up a set o...   \n","1              a girl going into a wooden building .   \n","2   a little girl climbing into a wooden playhouse .   \n","3  a little girl climbing the stairs to her playh...   \n","4  a little girl in a pink dress going into a woo...   \n","\n","                                     bengali_caption  \n","0  একটি গোলাপী জামা পরা বাচ্চা মেয়ে একটি বাড়ির প্...  \n","1             একটি মেয়ে শিশু একটি কাঠের বাড়িতে ঢুকছে  \n","2               একটি বাচ্চা তার কাঠের খেলাঘরে উঠছে ।  \n","3           ছোট মেয়েটি তার খেলার ঘরের সিড়ি বেয়ে উঠছে  \n","4  গোলাপি জামা পড়া ছোট একটি মেয়ে একটি কাঠের তৈরি...  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["file_path = \"../Sample Data/english to bengali.csv\"\n","pd.read_csv(file_path).head()"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T09:10:27.139998Z","iopub.status.busy":"2024-02-24T09:10:27.139712Z","iopub.status.idle":"2024-02-24T09:10:27.154802Z","shell.execute_reply":"2024-02-24T09:10:27.153829Z","shell.execute_reply.started":"2024-02-24T09:10:27.139973Z"},"trusted":true},"outputs":[],"source":["class BaseDataset(Dataset):\n","    def __init__(self, file_path: str, column: str, add_sos_eos: bool=False):\n","        self.df = pd.read_csv(file_path)\n","        self.sentences = self.df[column]\n","        self.vocabs = build_vocab_from_iterator(\n","            self.token_genarator(self.sentences)\n","            )\n","        self.add_sos_eos = add_sos_eos\n","        if self.add_sos_eos == True:\n","            extra_tokens = [\"<PAD>\", \"<SOS>\", \"<EOS>\", \"<UNK>\"]\n","            for token in extra_tokens:\n","                self.vocabs.append_token(token)\n","        else:\n","            extra_tokens = [\"<PAD>\", \"<UNK>\"]\n","            for token in extra_tokens:\n","                self.vocabs.append_token(token)\n","\n","    def token_genarator(self, sentences):\n","        for text in sentences:\n","            clean_text = \"\".join(\n","                [word for word in text \n","                 if word not in string.punctuation]\n","            )\n","            tokens = word_tokenize(clean_text)\n","            yield tokens\n","\n","    def text_to_sequences(self, sentences):\n","        sequence = [\n","            self.vocabs[token] if token in self.vocabs\n","            else self.vocabs[\"<UNK>\"]\n","            for token in word_tokenize(sentences)\n","            ]\n","        if self.add_sos_eos == True:\n","            sequence = [self.vocabs[\"<SOS>\"]] + sequence + [self.vocabs[\"<EOS>\"]]\n","\n","        return sequence\n","\n","    def __len__(self):\n","        return len(self.sentences)\n","    \n","    def __getitem__(self, index):\n","        item = self.sentences[index]\n","        sequence = self.text_to_sequences(item)\n","        return torch.tensor(sequence)\n","    \n","\n","class CombineDataset(Dataset):\n","    def __init__(self, data_path, eng_column, ban_column):\n","        self.eng_data = BaseDataset(\n","            file_path= data_path,\n","            column = eng_column, \n","            add_sos_eos=True,\n","        )\n","        self.bng_data = BaseDataset(\n","            file_path= data_path,\n","            column = ban_column,\n","            add_sos_eos=True\n","        )\n","\n","    @staticmethod\n","    def collate_fn(batch):\n","        en, bn = zip(*batch)\n","        # en = [item[0] for item in batch]\n","        # bn = [item[1] for item in batch]\n","        en_padded = pad_sequence(en, padding_value=0, batch_first=False)\n","        bn_padded = pad_sequence(bn, padding_value=0, batch_first=False)\n","        return en_padded, bn_padded \n","\n","    def __len__(self):\n","        return len(self.eng_data)\n","    \n","    def __getitem__(self, index):\n","        eng_item = self.eng_data[index]\n","        bng_item = self.bng_data[index]\n","        return eng_item, bng_item"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T09:10:27.156180Z","iopub.status.busy":"2024-02-24T09:10:27.155913Z","iopub.status.idle":"2024-02-24T09:10:27.168685Z","shell.execute_reply":"2024-02-24T09:10:27.167721Z","shell.execute_reply.started":"2024-02-24T09:10:27.156157Z"},"trusted":true},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, input_size, embed_size, hidden_size, n_layers, dropout_rate, debugging=False):\n","        super(Encoder, self).__init__()\n","        self.debugging = debugging\n","        self.embed_layer = nn.Embedding(input_size, embed_size)\n","        self.rnn_layer = nn.GRU(embed_size, hidden_size, n_layers)\n","        self.dropout_layer = nn.Dropout(p=dropout_rate)\n","\n","    def forward(self, source):\n","        # Apply dropout and get embedding\n","        embedding = self.dropout_layer(self.embed_layer(source))\n","        # Unpack RNN\n","        output, hidden = self.rnn_layer(embedding)\n","\n","        if self.debugging:\n","            print(\"Encoder Embedding Shape\", embedding.shape)\n","            print(\"Encoder Output Shape\", output.shape)\n","            print(\"Encoder Hidden Shape\", hidden.shape)\n","            \n","        return output, hidden"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T09:10:27.171780Z","iopub.status.busy":"2024-02-24T09:10:27.171295Z","iopub.status.idle":"2024-02-24T09:10:27.181804Z","shell.execute_reply":"2024-02-24T09:10:27.180996Z","shell.execute_reply.started":"2024-02-24T09:10:27.171749Z"},"trusted":true},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, output_size, embed_size, hidden_size, n_layers, dropout_rate, debugging=False):\n","        super(Decoder, self).__init__()\n","        self.debugging = debugging\n","        self.embed_layer = nn.Embedding(output_size, embed_size)\n","        self.rnn_layer = nn.GRU(embed_size, hidden_size, n_layers)\n","        self.fc_layer = nn.Linear(hidden_size, output_size)\n","        self.dropout_layer = nn.Dropout(p=dropout_rate)\n","\n","    def forward(self, input, encoder_hidden):\n","        #Input shape (batch_size) so we have to add an extra dim (1, batch_size)\n","        input = input.unsqueeze(0)\n","        embed = self.dropout_layer(self.embed_layer(input))\n","        #embed size (1, batch_size, embed_size)\n","        #encoder hidden shape (layer_size, batch_size, hidden_size)\n","        output, hidden = self.rnn_layer(embed, encoder_hidden)\n","        prediction = self.fc_layer(output)\n","        #prediction shape (1, batch_size, target_vocab_size) but need (batch_size, target_vocab_size)\n","        prediction = prediction.squeeze(0)\n","\n","        if self.debugging:\n","            print(\"Decoder Embedding Shape\", embed.shape)\n","            print(\"Decoder Input Shape\", input.shape)\n","            print(\"Decoder Prediction Shape\", prediction.shape)\n","            print(\"Decoder Hidden Shape\", hidden.shape)\n","\n","        return prediction, hidden"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T09:10:27.183157Z","iopub.status.busy":"2024-02-24T09:10:27.182894Z","iopub.status.idle":"2024-02-24T09:10:27.194883Z","shell.execute_reply":"2024-02-24T09:10:27.194068Z","shell.execute_reply.started":"2024-02-24T09:10:27.183133Z"},"trusted":true},"outputs":[],"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, output_size):\n","        super(Seq2Seq, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.output_size = output_size\n","\n","    def forward(self, source, target, tfr=0.5):\n","        batch_size = source.shape[1]\n","        seq_len = target.shape[0]\n","\n","        encoder_output, encoder_hidden = self.encoder(source)\n","        # Start with the first word of the target \"<SOS>\"\n","        start = target[0]\n","        outputs = torch.zeros(seq_len, batch_size, self.output_size).to(device)\n","        for t in range(1, seq_len):\n","            decoder_output, decoder_hidden = self.decoder(start, encoder_hidden)\n","            outputs[t] = decoder_output\n","\n","            top_pred = decoder_output.argmax(1)\n","            start = (target[t] if random.random() < tfr else top_pred)\n","            \n","        return outputs"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T09:10:27.196975Z","iopub.status.busy":"2024-02-24T09:10:27.195950Z","iopub.status.idle":"2024-02-24T09:10:27.208943Z","shell.execute_reply":"2024-02-24T09:10:27.208146Z","shell.execute_reply.started":"2024-02-24T09:10:27.196938Z"},"trusted":true},"outputs":[],"source":["def train_fn(model, loss_fn, dataloader, optimizer, device, clip_size=1.0):\n","    model.train()\n","    current_loss = 0.0\n","    \n","    for batch, (source, target) in enumerate(dataloader):\n","        source = source.to(device)\n","        target = target.to(device)\n","\n","        optimizer.zero_grad()\n","        output = model(source, target)\n","        output = output[1:].reshape(-1, output.shape[-1])\n","        target = target[1:].reshape(-1)\n","        loss = loss_fn(output, target)\n","\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_size)\n","        optimizer.step()\n","\n","        current_loss += loss.item()\n","    avg_loss = current_loss / len(dataloader)\n","    return avg_loss"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T09:10:27.210374Z","iopub.status.busy":"2024-02-24T09:10:27.210112Z","iopub.status.idle":"2024-02-24T09:10:27.219064Z","shell.execute_reply":"2024-02-24T09:10:27.218271Z","shell.execute_reply.started":"2024-02-24T09:10:27.210352Z"},"trusted":true},"outputs":[],"source":["def evaluate_fn(model, loss_fn, dataloader, device):\n","    model.eval()\n","    current_loss = 0.0\n","    \n","    with torch.no_grad():\n","        for batch, (source, target) in enumerate(dataloader):\n","            source = source.to(device)\n","            target = target.to(device)\n","\n","            output = model(source, target)\n","            output = output[1:].reshape(-1, output.shape[-1])\n","            target = target[1:].reshape(-1)\n","            loss = loss_fn(output, target)\n","\n","            current_loss += loss.item()\n","\n","    avg_loss = current_loss / len(dataloader)\n","    return avg_loss"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T09:10:27.220245Z","iopub.status.busy":"2024-02-24T09:10:27.219998Z","iopub.status.idle":"2024-02-24T09:10:41.106608Z","shell.execute_reply":"2024-02-24T09:10:41.105665Z","shell.execute_reply.started":"2024-02-24T09:10:27.220222Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([33, 512]) torch.Size([27, 512])\n","Bangla Vocabs: 16744\n","English Vocabs: 8748\n"]}],"source":["dataset = CombineDataset(\n","    data_path=\"/kaggle/input/english-to-bengali-for-machine-translation/english to bengali.csv\",\n","    eng_column=\"english_caption\", ban_column=\"bengali_caption\")\n","\n","dataloader = DataLoader(\n","    dataset,\n","    batch_size=512,\n","    shuffle=True,\n","    collate_fn=dataset.collate_fn)\n","\n","english, bangla = next(iter(dataloader))\n","print(english.shape, bangla.shape)\n","print(f\"Bangla Vocabs: {len(dataset.bng_data.vocabs)}\")\n","print(f\"English Vocabs: {len(dataset.eng_data.vocabs)}\")\n","\n","input_size = len(dataset.eng_data.vocabs)\n","output_size = len(dataset.bng_data.vocabs)\n","embed_size = 500\n","hidden_size = 128\n","n_layers = 1\n","dropout_rate = 0.1\n","lr_rate = 0.01\n","\n","encoder = Encoder(\n","    input_size, \n","    embed_size, \n","    hidden_size, \n","    n_layers, \n","    dropout_rate).to(device)\n","decoder = Decoder(\n","    output_size, \n","    embed_size, \n","    hidden_size, \n","    n_layers, \n","    dropout_rate).to(device)\n","\n","model = Seq2Seq(encoder, decoder, output_size).to(device)\n","\n","pad_idx = dataset.bng_data.vocabs[\"<PAD>\"]\n","loss_fn = torch.nn.CrossEntropyLoss(ignore_index=pad_idx)\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr_rate)"]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T09:10:41.108084Z","iopub.status.busy":"2024-02-24T09:10:41.107799Z","iopub.status.idle":"2024-02-24T09:32:32.544867Z","shell.execute_reply":"2024-02-24T09:32:32.543990Z","shell.execute_reply.started":"2024-02-24T09:10:41.108059Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":[" 10%|█         | 1/10 [02:09<19:25, 129.46s/it]"]},{"name":"stdout","output_type":"stream","text":["Train Loss 3.0242136360762957\n","Validation Loss 2.543363803392881\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 2/10 [04:19<17:19, 129.91s/it]"]},{"name":"stdout","output_type":"stream","text":["Train Loss 2.602988229169474\n","Validation Loss 2.4377011772874115\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|███       | 3/10 [06:31<15:16, 130.95s/it]"]},{"name":"stdout","output_type":"stream","text":["Train Loss 2.4374144154709656\n","Validation Loss 2.3145221502749953\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 4/10 [08:44<13:09, 131.66s/it]"]},{"name":"stdout","output_type":"stream","text":["Train Loss 2.30901465787516\n","Validation Loss 2.2233435627701996\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 5/10 [10:57<11:00, 132.00s/it]"]},{"name":"stdout","output_type":"stream","text":["Train Loss 2.261038986119357\n","Validation Loss 2.1581644562931803\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 6/10 [13:10<08:49, 132.38s/it]"]},{"name":"stdout","output_type":"stream","text":["Train Loss 2.2437540494002306\n","Validation Loss 2.1386744465146745\n"]},{"name":"stderr","output_type":"stream","text":[" 70%|███████   | 7/10 [15:22<06:37, 132.40s/it]"]},{"name":"stdout","output_type":"stream","text":["Train Loss 2.1654809759808824\n","Validation Loss 2.1134472125536434\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 8/10 [17:33<04:23, 131.84s/it]"]},{"name":"stdout","output_type":"stream","text":["Train Loss 2.133637058270442\n","Validation Loss 2.0551144627781657\n"]},{"name":"stderr","output_type":"stream","text":[" 90%|█████████ | 9/10 [19:42<02:11, 131.06s/it]"]},{"name":"stdout","output_type":"stream","text":["Train Loss 2.0964670475427205\n","Validation Loss 2.0448613352589793\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10/10 [21:51<00:00, 131.14s/it]"]},{"name":"stdout","output_type":"stream","text":["Train Loss 2.1328918779051147\n","Validation Loss 2.031452330675992\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["epochs = 10\n","for epoch in tqdm(range(epochs)):\n","    train_loss = train_fn(model, loss_fn,dataloader,optimizer,device)\n","    val_loss = evaluate_fn(model, loss_fn, dataloader, device)\n","    print(\"Train Loss\", train_loss)\n","    print(\"Validation Loss\", val_loss)"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T09:33:00.615199Z","iopub.status.busy":"2024-02-24T09:33:00.614854Z","iopub.status.idle":"2024-02-24T09:33:00.744352Z","shell.execute_reply":"2024-02-24T09:33:00.743571Z","shell.execute_reply.started":"2024-02-24T09:33:00.615171Z"},"trusted":true},"outputs":[],"source":["# torch.save(model.state_dict(), \"Seq2Seq_Model\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T09:33:12.189824Z","iopub.status.busy":"2024-02-24T09:33:12.189467Z","iopub.status.idle":"2024-02-24T09:33:12.230815Z","shell.execute_reply":"2024-02-24T09:33:12.229809Z","shell.execute_reply.started":"2024-02-24T09:33:12.189795Z"},"trusted":true},"outputs":[],"source":["# model.load_state_dict(torch.load(\"/kaggle/working/Seq2Seq_Model\", map_location=device))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T09:33:49.490620Z","iopub.status.busy":"2024-02-24T09:33:49.489736Z","iopub.status.idle":"2024-02-24T09:33:49.505921Z","shell.execute_reply":"2024-02-24T09:33:49.505022Z","shell.execute_reply.started":"2024-02-24T09:33:49.490582Z"},"trusted":true},"outputs":[],"source":["def translate_sentence(sentence, model=model, dataset=dataset, device=device):\n","    model.eval()\n","    with torch.no_grad():\n","        tokens = [token for token in word_tokenize(sentence)]\n","        tokens = [\"<SOS>\"] + tokens + [\"<EOS>\"]\n","        indices = dataset.eng_data.vocabs.lookup_indices(tokens)\n","        \n","        tensor = torch.LongTensor(indices).unsqueeze(-1).to(device)\n","        _, hidden = model.encoder(tensor)\n","        inputs = dataset.bng_data.vocabs.lookup_indices([\"<SOS>\"])\n","        \n","        for _ in range(len(sentence)):\n","            inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n","            output, hidden = model.decoder(inputs_tensor, hidden)\n","            predicted_token = output.argmax(1)\n","            inputs.append(predicted_token)\n","            if predicted_token == dataset.bng_data.vocabs[\"<EOS>\"]:\n","                break\n","        tokens = dataset.bng_data.vocabs.lookup_tokens(inputs)\n","    return \" \".join(tokens)\n","\n","sentence = \"a girl\"\n","translate_sentence(sentence)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4485439,"sourceId":7689472,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
